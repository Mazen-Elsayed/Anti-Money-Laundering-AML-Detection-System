{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f232b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ff0a0",
   "metadata": {},
   "source": [
    "## 1. Load Data and Prepare Train/Test Split\n",
    "\n",
    "Load the features and create the same train/test split as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac9ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "PROCESSED = os.path.abspath(os.path.join('..', 'data', 'processed'))\n",
    "features_path = os.path.join(PROCESSED, 'features.csv')\n",
    "\n",
    "if not os.path.exists(features_path):\n",
    "    print(f'ERROR: features.csv not found at {features_path}')\n",
    "else:\n",
    "    df = pd.read_csv(features_path)\n",
    "    print(f'Features loaded successfully')\n",
    "    print(f'Dataset shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590002a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column\n",
    "possible_target_names = ['is_laundering', 'is_fraud', 'label', 'target', 'fraud', 'laundering']\n",
    "target_col = None\n",
    "\n",
    "for col in possible_target_names:\n",
    "    if col in df.columns:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "print(f'Target column: {target_col}')\n",
    "\n",
    "# Check class distribution\n",
    "print(f'\\nOriginal class distribution:')\n",
    "print(df[target_col].value_counts())\n",
    "print(f'\\nClass proportions:')\n",
    "print(df[target_col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "exclude_cols = [target_col, 'id', 'transaction_id', 'account_id', 'customer_id']\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified train/test split (same as baseline)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f'Training set: {X_train.shape[0]} samples')\n",
    "print(f'Test set: {X_test.shape[0]} samples')\n",
    "print(f'\\nTraining set class distribution:')\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2094f7",
   "metadata": {},
   "source": [
    "## 2. Baseline (No Imbalance Handling)\n",
    "\n",
    "First, let's train a standard Logistic Regression as our baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline Logistic Regression\n",
    "print('Training baseline Logistic Regression (no imbalance handling)...')\n",
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "baseline_precision = precision_score(y_test, y_pred_baseline)\n",
    "baseline_recall = recall_score(y_test, y_pred_baseline)\n",
    "baseline_f1 = f1_score(y_test, y_pred_baseline)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('BASELINE (No Imbalance Handling)')\n",
    "print('=' * 60)\n",
    "print(f'Accuracy:  {baseline_accuracy:.4f}')\n",
    "print(f'Precision: {baseline_precision:.4f}')\n",
    "print(f'Recall:    {baseline_recall:.4f}')\n",
    "print(f'F1 Score:  {baseline_f1:.4f}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8dc14",
   "metadata": {},
   "source": [
    "## 3. Technique 1: Class Weighting (Balanced)\n",
    "\n",
    "Use `class_weight='balanced'` to automatically adjust weights inversely proportional to class frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression with balanced class weights\n",
    "print('Training Logistic Regression with class_weight=\"balanced\"...')\n",
    "balanced_model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "balanced_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_balanced = balanced_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "balanced_accuracy = accuracy_score(y_test, y_pred_balanced)\n",
    "balanced_precision = precision_score(y_test, y_pred_balanced)\n",
    "balanced_recall = recall_score(y_test, y_pred_balanced)\n",
    "balanced_f1 = f1_score(y_test, y_pred_balanced)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('CLASS WEIGHTING (Balanced)')\n",
    "print('=' * 60)\n",
    "print(f'Accuracy:  {balanced_accuracy:.4f}')\n",
    "print(f'Precision: {balanced_precision:.4f}')\n",
    "print(f'Recall:    {balanced_recall:.4f}')\n",
    "print(f'F1 Score:  {balanced_f1:.4f}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8652f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for balanced model\n",
    "balanced_cm = confusion_matrix(y_test, y_pred_balanced)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(balanced_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix - Class Weighting (Balanced)')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "print(f'True Negatives:  {balanced_cm[0, 0]}')\n",
    "print(f'False Positives: {balanced_cm[0, 1]}')\n",
    "print(f'False Negatives: {balanced_cm[1, 0]}')\n",
    "print(f'True Positives:  {balanced_cm[1, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04f4c4",
   "metadata": {},
   "source": [
    "## 4. Technique 2: Random Under-Sampling\n",
    "\n",
    "Reduce the majority class by randomly removing samples to match the minority class size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c64e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Random Under-Sampling\n",
    "print('Applying Random Under-Sampling...')\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f'Original training set: {X_train.shape[0]} samples')\n",
    "print(f'After under-sampling: {X_train_rus.shape[0]} samples')\n",
    "print(f'\\nClass distribution after under-sampling:')\n",
    "print(y_train_rus.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression on under-sampled data\n",
    "print('Training Logistic Regression on under-sampled data...')\n",
    "rus_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rus_model.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Predictions on original test set\n",
    "y_pred_rus = rus_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rus_accuracy = accuracy_score(y_test, y_pred_rus)\n",
    "rus_precision = precision_score(y_test, y_pred_rus)\n",
    "rus_recall = recall_score(y_test, y_pred_rus)\n",
    "rus_f1 = f1_score(y_test, y_pred_rus)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('RANDOM UNDER-SAMPLING')\n",
    "print('=' * 60)\n",
    "print(f'Accuracy:  {rus_accuracy:.4f}')\n",
    "print(f'Precision: {rus_precision:.4f}')\n",
    "print(f'Recall:    {rus_recall:.4f}')\n",
    "print(f'F1 Score:  {rus_f1:.4f}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006157f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for under-sampling\n",
    "rus_cm = confusion_matrix(y_test, y_pred_rus)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(rus_cm, annot=True, fmt='d', cmap='Greens', cbar=False)\n",
    "plt.title('Confusion Matrix - Random Under-Sampling')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "print(f'True Negatives:  {rus_cm[0, 0]}')\n",
    "print(f'False Positives: {rus_cm[0, 1]}')\n",
    "print(f'False Negatives: {rus_cm[1, 0]}')\n",
    "print(f'True Positives:  {rus_cm[1, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e931115",
   "metadata": {},
   "source": [
    "## 5. Technique 3: Random Over-Sampling\n",
    "\n",
    "Increase the minority class by randomly duplicating samples to match the majority class size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Random Over-Sampling\n",
    "print('Applying Random Over-Sampling...')\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f'Original training set: {X_train.shape[0]} samples')\n",
    "print(f'After over-sampling: {X_train_ros.shape[0]} samples')\n",
    "print(f'\\nClass distribution after over-sampling:')\n",
    "print(y_train_ros.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d846a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression on over-sampled data\n",
    "print('Training Logistic Regression on over-sampled data...')\n",
    "ros_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "ros_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predictions on original test set\n",
    "y_pred_ros = ros_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "ros_accuracy = accuracy_score(y_test, y_pred_ros)\n",
    "ros_precision = precision_score(y_test, y_pred_ros)\n",
    "ros_recall = recall_score(y_test, y_pred_ros)\n",
    "ros_f1 = f1_score(y_test, y_pred_ros)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('RANDOM OVER-SAMPLING')\n",
    "print('=' * 60)\n",
    "print(f'Accuracy:  {ros_accuracy:.4f}')\n",
    "print(f'Precision: {ros_precision:.4f}')\n",
    "print(f'Recall:    {ros_recall:.4f}')\n",
    "print(f'F1 Score:  {ros_f1:.4f}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for over-sampling\n",
    "ros_cm = confusion_matrix(y_test, y_pred_ros)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(ros_cm, annot=True, fmt='d', cmap='Oranges', cbar=False)\n",
    "plt.title('Confusion Matrix - Random Over-Sampling')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "print(f'True Negatives:  {ros_cm[0, 0]}')\n",
    "print(f'False Positives: {ros_cm[0, 1]}')\n",
    "print(f'False Negatives: {ros_cm[1, 0]}')\n",
    "print(f'True Positives:  {ros_cm[1, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4240378",
   "metadata": {},
   "source": [
    "## 6. Compare All Imbalance Handling Techniques\n",
    "\n",
    "Side-by-side comparison of all approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3475a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison = pd.DataFrame({\n",
    "    'Technique': ['Baseline (No Handling)', 'Class Weighting', 'Under-Sampling', 'Over-Sampling'],\n",
    "    'Accuracy': [baseline_accuracy, balanced_accuracy, rus_accuracy, ros_accuracy],\n",
    "    'Precision': [baseline_precision, balanced_precision, rus_precision, ros_precision],\n",
    "    'Recall': [baseline_recall, balanced_recall, rus_recall, ros_recall],\n",
    "    'F1 Score': [baseline_f1, balanced_f1, rus_f1, ros_f1]\n",
    "})\n",
    "\n",
    "print('\\n' + '=' * 90)\n",
    "print('COMPARISON OF IMBALANCE HANDLING TECHNIQUES')\n",
    "print('=' * 90)\n",
    "print(comparison.to_string(index=False))\n",
    "print('=' * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison - Focus on Recall and F1\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "techniques = ['Baseline', 'Balanced', 'Under-Sample', 'Over-Sample']\n",
    "x_pos = np.arange(len(techniques))\n",
    "\n",
    "# Recall comparison\n",
    "recalls = [baseline_recall, balanced_recall, rus_recall, ros_recall]\n",
    "axes[0].bar(x_pos, recalls, color=['gray', 'blue', 'green', 'orange'], alpha=0.7)\n",
    "axes[0].set_ylabel('Recall')\n",
    "axes[0].set_title('Recall Comparison (Higher is Better for AML)')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(techniques, rotation=15, ha='right')\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# F1 comparison\n",
    "f1_scores = [baseline_f1, balanced_f1, rus_f1, ros_f1]\n",
    "axes[1].bar(x_pos, f1_scores, color=['gray', 'blue', 'green', 'orange'], alpha=0.7)\n",
    "axes[1].set_ylabel('F1 Score')\n",
    "axes[1].set_title('F1 Score Comparison')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(techniques, rotation=15, ha='right')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All metrics comparison\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(x - 1.5*width, [baseline_accuracy, baseline_precision, baseline_recall, baseline_f1], \n",
    "       width, label='Baseline', alpha=0.8)\n",
    "ax.bar(x - 0.5*width, [balanced_accuracy, balanced_precision, balanced_recall, balanced_f1], \n",
    "       width, label='Class Weighting', alpha=0.8)\n",
    "ax.bar(x + 0.5*width, [rus_accuracy, rus_precision, rus_recall, rus_f1], \n",
    "       width, label='Under-Sampling', alpha=0.8)\n",
    "ax.bar(x + 1.5*width, [ros_accuracy, ros_precision, ros_recall, ros_f1], \n",
    "       width, label='Over-Sampling', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('All Metrics Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e0209",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "**1. Baseline (No Imbalance Handling):**\n",
    "- May have high accuracy but likely poor recall for the minority class (fraud cases)\n",
    "- Not suitable for AML detection where missing fraud is costly\n",
    "\n",
    "**2. Class Weighting (Balanced):**\n",
    "- Simple to implement - just add `class_weight='balanced'` parameter\n",
    "- Usually improves recall significantly\n",
    "- No change to training data size\n",
    "- Good first approach for imbalanced problems\n",
    "\n",
    "**3. Random Under-Sampling:**\n",
    "- Reduces training data size significantly\n",
    "- May lose important information from majority class\n",
    "- Often improves recall but can reduce precision\n",
    "- Fast training due to smaller dataset\n",
    "\n",
    "**4. Random Over-Sampling:**\n",
    "- Increases training data size by duplicating minority samples\n",
    "- Risk of overfitting to minority class\n",
    "- Usually improves recall\n",
    "- Slower training due to larger dataset\n",
    "\n",
    "### Which Method Helped Most?\n",
    "\n",
    "For **AML detection**, we prioritize **recall** (catching as many fraud cases as possible) over accuracy.\n",
    "\n",
    "Based on the results:\n",
    "- **Class weighting** is often the best starting point - simple and effective\n",
    "- **Over-sampling** can provide better recall if you have sufficient compute resources\n",
    "- **Under-sampling** works well when you have a very large dataset\n",
    "\n",
    "### Recommendation:\n",
    "\n",
    "Use **class weighting** or **over-sampling** for the next steps with advanced models. These techniques balance the trade-off between catching fraud cases and maintaining reasonable precision."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
